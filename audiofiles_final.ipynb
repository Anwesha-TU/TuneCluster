{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a4a2ec0-2c17-4466-b3d9-8e71c8bffdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3873e638-3108-4597-a273-6a27e405f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "   'https://youtu.be/T71ZyjvCtOA?si=edERKHxJN3pIlwqy',\n",
    "    'https://youtu.be/ku4k6DQdoDs?si=ihlGALAEGLCv7lVa',\n",
    "    'https://youtu.be/09839DpTctU?si=LMhr529Vdg_FqZG9',\n",
    "    'https://youtu.be/YlUKcNNmywk?si=YRI8wiHMaLOosYqf',\n",
    "    'https://youtu.be/tAGnKpE4NCI?si=T87MMRaSq26y6hFn',\n",
    "    'https://youtu.be/nyq9r8OYmn0?si=CYwk69ee4SPOPUh0',\n",
    "    'https://youtu.be/agYzgxruck0?si=uFxvapOusuAjObxQ',\n",
    "    'https://youtu.be/WeY9hdsmIaQ?si=F5hQtkWJPrQbwCnu',\n",
    "    'https://youtu.be/h1PMLoiiliA?si=-NX-ax7XagpT2Ni0',\n",
    "    'https://youtu.be/4mLAIoqLYuQ?si=IrlRmOh0hG4kqp0t',\n",
    "    'https://youtu.be/wiO2VJCMgUo?si=Lw5uZHy1maMxdDCE',\n",
    "    'https://youtu.be/vx2u5uUu3DE?si=_KHthhvOK5c-yteE',\n",
    "    'https://youtu.be/NvR60Wg9R7Q?si=U1pvdTmdyMHKdxOC',\n",
    "    'https://youtu.be/QkF3oxziUI4?si=_sdZ6M8qL65XFyJl',\n",
    "    'https://youtu.be/CD-E-LDc384?si=vS2SznV8IhrGp4GP',\n",
    "    'https://youtu.be/E0ozmU9cJDg?si=det63ZvlpM9ZtWkM',\n",
    "    'https://youtu.be/1w7OgIMMRc4?si=AYB26yXb9amLiq3W',\n",
    "    'https://youtu.be/hTWKbfoikeg?si=rT8bgT2i9k02plUk',\n",
    "    'https://youtu.be/fJ9rUzIMcZQ?si=VJNH4FsVujFvU1Iw',\n",
    "    'https://youtu.be/8SbUC-UaAxE?si=BJHG9nqAD6qqWIKe',\n",
    "    'https://youtu.be/v2AC41dglnM?si=0PldLN7vKvj0g69K',\n",
    "    'https://youtu.be/89dGC8de0CA?si=mLE-rkG_xbWZrUqY',\n",
    "    'https://youtu.be/7f3EGjRxxNI?si=Ue96BY0RtDkcApIq',\n",
    "    'https://youtu.be/x3sFsHrUyLQ?si=eUC6vGUH7kiYjn-w',\n",
    "    'https://youtu.be/CWUGikRxGQs?si=VmabBwHZor2eR0hq',\n",
    "    'https://youtu.be/k8gx-C7GCGU?si=8GiupYewWxv7JaFZ',\n",
    "    'https://youtu.be/EwLMA5XYnKI?si=7k85ic6s94jxtHiD',\n",
    "    'https://youtu.be/1-1TGNmQqZA?si=bns4230juoCXeLZp',\n",
    "    'https://youtu.be/fGubAEGT8f4?si=yoMAjVAJbp6o4ghR',\n",
    "    'https://youtu.be/atWpuwRcMoc?si=66-_xEnIlcypoUEH',\n",
    "    'https://youtu.be/Opxhh9Oh3rg?si=6ZN3OJJlLyD1wN7O',\n",
    "    'https://youtu.be/igvP806798U?si=QEnuQ-cMsK_d-GzP',\n",
    "    'https://youtu.be/pAgnJDJN4VA?si=NPt3drmJW8RbYUmu',\n",
    "    'https://youtu.be/A_MjCqQoLLA?si=veiqQNnU7CigghyF',\n",
    "    'https://youtu.be/r00ikilDxW4?si=1TgdCs3D9ap_Fud9',\n",
    "    'https://youtu.be/pGhwBFYtn1s?si=oYhRexTVzpNxvuh-',\n",
    "    'https://youtu.be/Soa3gO7tL-c?si=dqTkGU8dDMU-l-aj',\n",
    "    'https://youtu.be/eVTXPUF4Oz4?si=oepvB4oxXP3nyctC',\n",
    "    'https://youtu.be/FmE9DQgdNm8?si=C0F2M7pcinHdIt8b',\n",
    "    'https://youtu.be/eCCT-cgMHDc?si=IazT24Och4gL7gkj'\n",
    "    \n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53ca990e-4e53-4759-92b3-60e236041814",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"C:/Users/acann/OneDrive/Desktop/ml project/datasets/rock\"\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8355d7d-1577-4ee3-90fe-ed442f81bca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: song_1\n",
      "Downloaded: song_2\n",
      "Downloaded: song_3\n",
      "Downloaded: song_4\n",
      "Downloaded: song_5\n",
      "Downloaded: song_6\n",
      "Downloaded: song_7\n",
      "Downloaded: song_8\n",
      "Downloaded: song_9\n",
      "Downloaded: song_10\n",
      "Downloaded: song_11\n",
      "Downloaded: song_12\n",
      "Downloaded: song_13\n",
      "Downloaded: song_14\n",
      "Downloaded: song_15\n",
      "Downloaded: song_16\n",
      "Downloaded: song_17\n",
      "Downloaded: song_18\n",
      "Downloaded: song_19\n",
      "Downloaded: song_20\n",
      "Downloaded: song_21\n",
      "Downloaded: song_22\n",
      "Downloaded: song_23\n",
      "Downloaded: song_24\n",
      "Downloaded: song_25\n",
      "Downloaded: song_26\n",
      "Downloaded: song_27\n",
      "Downloaded: song_28\n",
      "Downloaded: song_29\n",
      "Downloaded: song_30\n",
      "Downloaded: song_31\n",
      "Downloaded: song_32\n",
      "Downloaded: song_33\n",
      "Downloaded: song_34\n",
      "Downloaded: song_35\n",
      "Downloaded: song_36\n",
      "Downloaded: song_37\n",
      "Downloaded: song_38\n",
      "Downloaded: song_39\n",
      "Downloaded: song_40\n"
     ]
    }
   ],
   "source": [
    "for i, url in enumerate(urls, start=1):\n",
    "    try:\n",
    "        subprocess.run([\n",
    "            \"yt-dlp\", \"-x\", \"--audio-format\", \"mp3\",\n",
    "            \"-o\", f\"{save_path}/song_{i}.%(ext)s\", url\n",
    "        ], check=True)\n",
    "        print(f\"Downloaded: song_{i}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Failed to download {url} - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c22a49e4-2378-498d-88f7-63eed0e6ab7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting librosa\n",
      "  Downloading librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Downloading audioread-3.1.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\acann\\anaconda3\\lib\\site-packages (from librosa) (0.61.0)\n",
      "Requirement already satisfied: numpy>=1.22.3 in c:\\users\\acann\\anaconda3\\lib\\site-packages (from librosa) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\acann\\anaconda3\\lib\\site-packages (from librosa) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\acann\\anaconda3\\lib\\site-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\acann\\anaconda3\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\acann\\anaconda3\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Collecting soundfile>=0.12.1 (from librosa)\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl.metadata (16 kB)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Downloading soxr-1.0.0-cp312-abi3-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in c:\\users\\acann\\anaconda3\\lib\\site-packages (from librosa) (4.15.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\acann\\anaconda3\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\acann\\anaconda3\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Collecting standard-aifc (from librosa)\n",
      "  Downloading standard_aifc-3.13.0-py3-none-any.whl.metadata (969 bytes)\n",
      "Collecting standard-sunau (from librosa)\n",
      "  Downloading standard_sunau-3.13.0-py3-none-any.whl.metadata (914 bytes)\n",
      "Requirement already satisfied: packaging in c:\\users\\acann\\anaconda3\\lib\\site-packages (from lazy_loader>=0.1->librosa) (24.2)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\acann\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\acann\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (4.3.7)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\acann\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\acann\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acann\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acann\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acann\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.10.5)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\acann\\anaconda3\\lib\\site-packages (from scikit-learn>=1.1.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\acann\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\acann\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Collecting standard-chunk (from standard-aifc->librosa)\n",
      "  Downloading standard_chunk-3.13.0-py3-none-any.whl.metadata (860 bytes)\n",
      "Collecting audioop-lts (from standard-aifc->librosa)\n",
      "  Downloading audioop_lts-0.2.2-cp313-abi3-win_amd64.whl.metadata (2.0 kB)\n",
      "Downloading librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Downloading audioread-3.1.0-py3-none-any.whl (23 kB)\n",
      "Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.5/1.0 MB 417.9 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 0.5/1.0 MB 417.9 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 0.8/1.0 MB 472.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 569.0 kB/s eta 0:00:00\n",
      "Downloading soxr-1.0.0-cp312-abi3-win_amd64.whl (172 kB)\n",
      "Downloading standard_aifc-3.13.0-py3-none-any.whl (10 kB)\n",
      "Downloading audioop_lts-0.2.2-cp313-abi3-win_amd64.whl (30 kB)\n",
      "Downloading standard_chunk-3.13.0-py3-none-any.whl (4.9 kB)\n",
      "Downloading standard_sunau-3.13.0-py3-none-any.whl (7.4 kB)\n",
      "Installing collected packages: standard-chunk, soxr, audioop-lts, standard-sunau, standard-aifc, soundfile, pooch, audioread, librosa\n",
      "\n",
      "   ----------------- ---------------------- 4/9 [standard-aifc]\n",
      "   -------------------------- ------------- 6/9 [pooch]\n",
      "   -------------------------- ------------- 6/9 [pooch]\n",
      "   ----------------------------------- ---- 8/9 [librosa]\n",
      "   ----------------------------------- ---- 8/9 [librosa]\n",
      "   ----------------------------------- ---- 8/9 [librosa]\n",
      "   ----------------------------------- ---- 8/9 [librosa]\n",
      "   ----------------------------------- ---- 8/9 [librosa]\n",
      "   ----------------------------------- ---- 8/9 [librosa]\n",
      "   ---------------------------------------- 9/9 [librosa]\n",
      "\n",
      "Successfully installed audioop-lts-0.2.2 audioread-3.1.0 librosa-0.11.0 pooch-1.8.2 soundfile-0.13.1 soxr-1.0.0 standard-aifc-3.13.0 standard-chunk-3.13.0 standard-sunau-3.13.0\n"
     ]
    }
   ],
   "source": [
    "pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b1de887-0724-400a-b8a4-37a5b8a4e973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa, soundfile as sf, glob, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85439e71-2506-4a79-92f9-eaa2103f083c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted: song_1.wav\n",
      "Converted: song_10.wav\n",
      "Converted: song_11.wav\n",
      "Converted: song_12.wav\n",
      "Converted: song_13.wav\n",
      "Converted: song_14.wav\n",
      "Converted: song_15.wav\n",
      "Converted: song_16.wav\n",
      "Converted: song_17.wav\n",
      "Converted: song_18.wav\n",
      "Converted: song_19.wav\n",
      "Converted: song_2.wav\n",
      "Converted: song_20.wav\n",
      "Converted: song_21.wav\n",
      "Converted: song_22.wav\n",
      "Converted: song_23.wav\n",
      "Converted: song_24.wav\n",
      "Converted: song_25.wav\n",
      "Converted: song_26.wav\n",
      "Converted: song_27.wav\n",
      "Converted: song_28.wav\n",
      "Converted: song_29.wav\n",
      "Converted: song_3.wav\n",
      "Converted: song_30.wav\n",
      "Converted: song_31.wav\n",
      "Converted: song_32.wav\n",
      "Converted: song_33.wav\n",
      "Converted: song_34.wav\n",
      "Converted: song_35.wav\n",
      "Converted: song_36.wav\n",
      "Converted: song_37.wav\n",
      "Converted: song_38.wav\n",
      "Converted: song_39.wav\n",
      "Converted: song_4.wav\n",
      "Converted: song_40.wav\n",
      "Converted: song_5.wav\n",
      "Converted: song_6.wav\n",
      "Converted: song_7.wav\n",
      "Converted: song_8.wav\n",
      "Converted: song_9.wav\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_path = r\"C:\\Users\\acann\\OneDrive\\Desktop\\ml project\\datasets\\rock\"\n",
    "\n",
    "for mp3 in glob.glob(os.path.join(input_path, \"*.mp3\")):\n",
    "    try:\n",
    "        y, sr = librosa.load(mp3, sr=44100, mono=True)\n",
    "        wav_path = os.path.splitext(mp3)[0] + \".wav\"\n",
    "        sf.write(wav_path, y, sr)\n",
    "        print(f\"Converted: {os.path.basename(wav_path)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed {mp3} - {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36537322-3d81-447a-a4af-ce24a632561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9386d98-78b5-4820-86d1-0dc994c0072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = r\"C:\\Users\\acann\\OneDrive\\Desktop\\ml project\\datasets\\rock\"\n",
    "output_path = os.path.join(input_path, \"processed\")\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2441a84-7e97-4c62-b116-47a49bd5673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DURATION = 30        # seconds\n",
    "SR = 44100\n",
    "SAMPLES_30S = SR * DURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c944763-440f-48b1-828d-a34309a1e2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ffe2230-b708-40a8-8fa3-53712a324f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processed: song_1.wav\n",
      " Processed: song_10.wav\n",
      " Processed: song_11.wav\n",
      " Processed: song_12.wav\n",
      " Processed: song_13.wav\n",
      " Processed: song_14.wav\n",
      " Processed: song_15.wav\n",
      " Processed: song_16.wav\n",
      " Processed: song_17.wav\n",
      " Processed: song_18.wav\n",
      " Processed: song_19.wav\n",
      " Processed: song_2.wav\n",
      " Processed: song_20.wav\n",
      " Processed: song_21.wav\n",
      " Processed: song_22.wav\n",
      " Processed: song_23.wav\n",
      " Processed: song_24.wav\n",
      " Processed: song_25.wav\n",
      " Processed: song_26.wav\n",
      " Processed: song_27.wav\n",
      " Processed: song_28.wav\n",
      " Processed: song_29.wav\n",
      " Processed: song_3.wav\n",
      " Processed: song_30.wav\n",
      " Processed: song_31.wav\n",
      " Processed: song_32.wav\n",
      " Processed: song_33.wav\n",
      " Processed: song_34.wav\n",
      " Processed: song_35.wav\n",
      " Processed: song_36.wav\n",
      " Processed: song_37.wav\n",
      " Processed: song_38.wav\n",
      " Processed: song_39.wav\n",
      " Processed: song_4.wav\n",
      " Processed: song_40.wav\n",
      " Processed: song_5.wav\n",
      " Processed: song_6.wav\n",
      " Processed: song_7.wav\n",
      " Processed: song_8.wav\n",
      " Processed: song_9.wav\n"
     ]
    }
   ],
   "source": [
    "for wav_file in glob.glob(os.path.join(input_path, \"*.wav\")):\n",
    "    try:\n",
    "        y, sr = librosa.load(wav_file, sr=SR, mono=True)\n",
    "        total_len = len(y)\n",
    "\n",
    "        if total_len > SAMPLES_30S:\n",
    "            start = random.randint(0, total_len - SAMPLES_30S)\n",
    "            y = y[start:start + SAMPLES_30S]\n",
    "        else:\n",
    "            y = librosa.util.fix_length(y, size=SAMPLES_30S)\n",
    "\n",
    "        max_val = np.max(np.abs(y))\n",
    "        if max_val != 0:\n",
    "            y = y / max_val\n",
    "\n",
    "        base = os.path.basename(wav_file)\n",
    "        save_path = os.path.join(output_path, base)\n",
    "        sf.write(save_path, y, sr)\n",
    "        print(f\" Processed: {base}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Failed {wav_file} - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "111bad32-a13e-4043-aea7-ef0521d8329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import rfft, rfftfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "385a283d-8f69-43bf-a530-cd3a632cab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path  = r\"C:\\Users\\acann\\OneDrive\\Desktop\\ml project\\datasets\\rock\\processed\" \n",
    "output_path = r\"C:\\Users\\acann\\OneDrive\\Desktop\\ml project\\datasets\\rock\\features_XM\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "SR = 44100\n",
    "DURATION = 30\n",
    "SAMPLES_30S = SR * DURATION\n",
    "\n",
    "n_mels = 20\n",
    "mel_edges = librosa.mel_frequencies(n_mels=n_mels + 1, fmin=0.0, fmax=2000.0)\n",
    "xm_bands = [(mel_edges[i], mel_edges[i + 1]) for i in range(len(mel_edges) - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84fea94c-4795-4080-8943-86acd5a979a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_xm_features(wav_path):\n",
    "    y, _ = librosa.load(wav_path, sr=None, mono=True)  # no resampling, already 44.1kHz mono\n",
    "    Y = np.abs(rfft(y))\n",
    "    freqs = rfftfreq(len(y), 1.0 / SR)\n",
    "\n",
    "    feats = []\n",
    "    for low, high in xm_bands:\n",
    "        mask = (freqs >= low) & (freqs < high)\n",
    "        feats.append(Y[mask].mean() if mask.any() else 0.0)\n",
    "\n",
    "    x = np.array(feats, dtype=float)\n",
    "    norm = np.linalg.norm(x)\n",
    "    if norm > 0:\n",
    "        x /= norm\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b51f3c8-2f1c-4ee7-9377-2205d53ef13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8769d69-a3a0-4312-874b-14b8ad5d3297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ song_1.wav\n",
      "✅ song_10.wav\n",
      "✅ song_11.wav\n",
      "✅ song_12.wav\n",
      "✅ song_13.wav\n",
      "✅ song_14.wav\n",
      "✅ song_15.wav\n",
      "✅ song_16.wav\n",
      "✅ song_17.wav\n",
      "✅ song_18.wav\n",
      "✅ song_19.wav\n",
      "✅ song_2.wav\n",
      "✅ song_20.wav\n",
      "✅ song_21.wav\n",
      "✅ song_22.wav\n",
      "✅ song_23.wav\n",
      "✅ song_24.wav\n",
      "✅ song_25.wav\n",
      "✅ song_26.wav\n",
      "✅ song_27.wav\n",
      "✅ song_28.wav\n",
      "✅ song_29.wav\n",
      "✅ song_3.wav\n",
      "✅ song_30.wav\n",
      "✅ song_31.wav\n",
      "✅ song_32.wav\n",
      "✅ song_33.wav\n",
      "✅ song_34.wav\n",
      "✅ song_35.wav\n",
      "✅ song_36.wav\n",
      "✅ song_37.wav\n",
      "✅ song_38.wav\n",
      "✅ song_39.wav\n",
      "✅ song_4.wav\n",
      "✅ song_40.wav\n",
      "✅ song_5.wav\n",
      "✅ song_6.wav\n",
      "✅ song_7.wav\n",
      "✅ song_8.wav\n",
      "✅ song_9.wav\n",
      "\n",
      " Saved C:\\Users\\acann\\OneDrive\\Desktop\\ml project\\datasets\\rock\\features_XM\\features_XM.csv  (shape = (40, 21))\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for wav_file in glob.glob(os.path.join(input_path, \"*.wav\")):\n",
    "    try:\n",
    "        feat = extract_xm_features(wav_file)\n",
    "        base = os.path.basename(wav_file)\n",
    "        rows.append([base, *feat])\n",
    "        print(f\"{base}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{wav_file} - {e}\")\n",
    "\n",
    "cols = [\"file\"] + [f\"f{i+1}\" for i in range(len(xm_bands))]\n",
    "df = pd.DataFrame(rows, columns=cols)\n",
    "csv_path = os.path.join(output_path, \"features_XM.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"\\n Saved {csv_path}  (shape = {df.shape})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e2ad367e-3478-46d3-a1f6-406836ff6c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7749a59-c59a-467b-93d4-c88e6c11148a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\acann\\OneDrive\\Desktop\\ml project\\processed and feature extracted_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3d53da5e-8338-4e19-b96d-89b13d1830ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7458df46-85e8-489e-81aa-28cbf9222654",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace('-', np.nan)\n",
    "df = df.dropna()\n",
    "X = df.iloc[:, 2:].values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1199b3e7-2c5f-43ff-8b90-dc43a2b727a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9acb9c59-ede8-422e-a53d-79585135664e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0b59edd6-89d3-426e-bd9b-2fc4cf4b2303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           File name      genre        f1  \\\n",
      "0  Hindustani Classical Vocal - Bandish - Sachi K...  classical  0.055238   \n",
      "1  Zindagi Se Badi Saza Hi Nahin ｜ Relaxing Sitar...  classical  0.008259   \n",
      "2  Hindustani Classical Vocal ｜ Kalpana Zokarkar｜...  classical  0.129947   \n",
      "3  Indian Classical Vocal ｜ Manjusha Kulkarni Pat...  classical  0.042809   \n",
      "4  Raga Darbari Kanhada - Pandit Jasraj (Album： T...  classical  0.058416   \n",
      "\n",
      "            f2        f3        f4        f5        f6        f7        f8  \\\n",
      "0   0.34256995  0.158805  0.406750  0.083513  0.114141  0.211138  0.366079   \n",
      "1  0.015218734  0.107816  0.413347  0.316100  0.279544  0.274531  0.367286   \n",
      "2   0.46471637  0.161825  0.251175  0.256754  0.341654  0.200203  0.207060   \n",
      "3     0.431102  0.195693  0.307134  0.232218  0.286155  0.080349  0.233229   \n",
      "4   0.46689004  0.280672  0.254930  0.254814  0.269564  0.313488  0.278635   \n",
      "\n",
      "   ...       f11       f12       f13       f14       f15       f16       f17  \\\n",
      "0  ...  0.287871  0.217894  0.160131  0.214323  0.126478  0.145346  0.149513   \n",
      "1  ...  0.146192  0.126726  0.226018  0.214868  0.201382  0.196535  0.410224   \n",
      "2  ...  0.228593  0.158175  0.141557  0.210543  0.162723  0.298471  0.115015   \n",
      "3  ...  0.394645  0.205280  0.082562  0.094391  0.226773  0.222644  0.140394   \n",
      "4  ...  0.200994  0.082644  0.056886  0.085197  0.114043  0.114656  0.148588   \n",
      "\n",
      "        f18       f19       f20  \n",
      "0  0.147130  0.086023  0.116300  \n",
      "1  0.083969  0.108025  0.043354  \n",
      "2  0.139077  0.151658  0.081131  \n",
      "3  0.130471  0.275391  0.114780  \n",
      "4  0.109091  0.073320  0.055592  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# print(df.dtypes)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "be21e458-bb4e-41e1-97e6-185f36a70fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acann\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8896f970-804f-4f3f-9d60-3363a660a5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cluster\"] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1bea3e7a-1516-49a2-8c6a-a8b4b98b264d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " K-Means completed with 4 clusters\n",
      " Silhouette Score: 0.4945\n"
     ]
    }
   ],
   "source": [
    "sil_score = silhouette_score(X_scaled, clusters)\n",
    "print(f\" K-Means completed with {k} clusters\")\n",
    "print(f\" Silhouette Score: {sil_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fdb201ad-a284-40e2-b151-66933217df63",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6c97a2b2-e4fd-412c-a486-97888ac10404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand Index (RI): 0.4731132075471698\n",
      "Adjusted Rand Index (ARI): 0.11004043835781181\n",
      "Normalized Mutual Info (NMI): 0.3188523591009973\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import rand_score, adjusted_rand_score, normalized_mutual_info_score\n",
    "\n",
    "RI = rand_score(y, clusters)\n",
    "ARI = adjusted_rand_score(y, clusters)\n",
    "NMI = normalized_mutual_info_score(y, clusters)\n",
    "\n",
    "print(\"Rand Index (RI):\", RI)\n",
    "print(\"Adjusted Rand Index (ARI):\", ARI)\n",
    "print(\"Normalized Mutual Info (NMI):\", NMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "08bf88c6-5397-4e70-91d9-d298a50b1dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity: 0.4312\n"
     ]
    }
   ],
   "source": [
    "def purity_score(y_true, y_pred):\n",
    "    contingency = pd.crosstab(y_true, y_pred)\n",
    "    return np.sum(np.max(contingency.values, axis=0)) / np.sum(contingency.values)\n",
    "\n",
    "purity = purity_score(y, clusters)\n",
    "print(\"Purity:\", round(purity, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb38ea13-4245-4246-a854-6fec29b5bec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster → Genre mapping: {np.int32(1): 'classical', np.int32(2): 'pop', np.int32(3): 'pop', np.int32(0): 'pop'}\n",
      "\n",
      "Confusion Matrix:\n",
      " [[40  0  0  0]\n",
      " [40  0  0  0]\n",
      " [40  0  0  0]\n",
      " [11  0  0 29]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "df_eval = pd.DataFrame({\"true\": y, \"cluster\": clusters})\n",
    "\n",
    "mapping = {}\n",
    "\n",
    "for c in df_eval[\"cluster\"].unique():\n",
    "    common = df_eval[df_eval[\"cluster\"] == c][\"true\"].mode()[0]\n",
    "    mapping[c] = common\n",
    "\n",
    "print(\"Cluster → Genre mapping:\", mapping)\n",
    "\n",
    "df_eval[\"predicted\"] = df_eval[\"cluster\"].map(mapping)\n",
    "cm = confusion_matrix(df_eval[\"true\"], df_eval[\"predicted\"],\n",
    "                      labels=[\"classical\", \"jazz\", \"rock\", \"pop\"])\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ce4bb2a-040b-4389-ac1d-07584797118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import rand_score\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3072bce1-f6d4-4a97-925a-712ef1427018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "classical    40\n",
       "pop          40\n",
       "jazz         40\n",
       "rock         40\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"genre\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0970fbde-b664-4f64-9833-b3e7a812c91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"genre\"] = df[\"genre\"].astype(str).str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a44ebfe-8fbc-445f-84d3-e185e2a170d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "classical    40\n",
       "pop          40\n",
       "jazz         40\n",
       "rock         40\n",
       "nan           3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"genre\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5f9f8f9-300e-44f7-960c-9c6a426536d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9e3acdb-7bf8-4e00-9f14-28329c814797",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = r\"C:\\Users\\acann\\OneDrive\\Desktop\\ml project\\processed and feature extracted_final.csv\"\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c3c790d-8c85-48fc-a534-549ddf15f315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['classical' 'pop' 'jazz' 'rock' nan]\n"
     ]
    }
   ],
   "source": [
    "print(df[\"genre\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a35b81d-904a-46c5-b526-477c61f082c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"genre\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7bf126bf-4c51-47bc-9944-b0abac2e6b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['classical' 'pop' 'jazz' 'rock']\n",
      "(160, 22)\n"
     ]
    }
   ],
   "source": [
    "print(df[\"genre\"].unique())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "692125b2-bf96-42e5-89e2-3f19aa2d80a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 2:].astype(float).values  \n",
    "y = df[\"genre\"].values                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "120bb433-4fc1-441a-afee-dc7ab449e7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "003b1f7b-d180-420d-9482-0257937a1362",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "X_pca = pca.fit_transform(X_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7bda855c-1cc8-4e59-8187-1e0f72cff61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "genres = df[\"genre\"].unique()\n",
    "\n",
    "initial_centroids = []\n",
    "for g in genres:\n",
    "    idx = df[df[\"genre\"] == g].index.tolist()\n",
    "    chosen = random.choice(idx)\n",
    "    initial_centroids.append(X_pca[chosen])\n",
    "\n",
    "initial_centroids = np.array(initial_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ed2c526-53bf-4de3-a814-79ca7baa1a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acann\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=4, init=initial_centroids, n_init=1, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_pca)\n",
    "\n",
    "df[\"cluster\"] = clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1904d9ac-4e70-49a3-8463-3d7ee61efb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand Index (RI): 0.7549528301886792\n",
      "Adjusted Rand Index (ARI): 0.36539015592407775\n",
      "Normalized Mutual Info (NMI): 0.4452294911579203\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import rand_score, adjusted_rand_score, normalized_mutual_info_score\n",
    "\n",
    "RI = rand_score(y, clusters)\n",
    "ARI = adjusted_rand_score(y, clusters)\n",
    "NMI = normalized_mutual_info_score(y, clusters)\n",
    "\n",
    "print(\"Rand Index (RI):\", RI)\n",
    "print(\"Adjusted Rand Index (ARI):\", ARI)\n",
    "print(\"Normalized Mutual Info (NMI):\", NMI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7592cd5-d1a7-41b8-a70c-d9ae90db83a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Silhouette Score: 0.1823\n"
     ]
    }
   ],
   "source": [
    "sil_score = silhouette_score(X_scaled, clusters)\n",
    "print(f\" Silhouette Score: {sil_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac159272-0a71-4620-baa1-e50a3fe92088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity: 0.6688\n"
     ]
    }
   ],
   "source": [
    "def purity_score(y_true, y_pred):\n",
    "    contingency = pd.crosstab(y_true, y_pred)\n",
    "    return np.sum(np.max(contingency.values, axis=0)) / np.sum(contingency.values)\n",
    "\n",
    "purity = purity_score(y, clusters)\n",
    "print(\"Purity:\", round(purity, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "51c2ffa6-0573-4a7b-8130-fd84d6b2ca0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster → Genre mapping: {np.int32(1): 'classical', np.int32(3): 'rock', np.int32(2): 'jazz', np.int32(0): 'pop'}\n",
      "\n",
      "Confusion Matrix:\n",
      " [[19  5 16  0]\n",
      " [ 0 39  1  0]\n",
      " [ 1 12 27  0]\n",
      " [11  1  6 22]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "df_eval = pd.DataFrame({\"true\": y, \"cluster\": clusters})\n",
    "mapping = {}\n",
    "for c in df_eval[\"cluster\"].unique():\n",
    "    common = df_eval[df_eval[\"cluster\"] == c][\"true\"].mode()[0]\n",
    "    mapping[c] = common\n",
    "print(\"Cluster → Genre mapping:\", mapping)\n",
    "df_eval[\"predicted\"] = df_eval[\"cluster\"].map(mapping)\n",
    "\n",
    "cm = confusion_matrix(df_eval[\"true\"], df_eval[\"predicted\"],\n",
    "                      labels=[\"classical\", \"jazz\", \"rock\", \"pop\"])\n",
    "\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049a7e67-9b2b-447e-9fe3-e51c96d530e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
